{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83ffee-0ae8-44e7-b732-21ad49f5763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy\n",
    "\n",
    "#\n",
    "import urllib.request, numpy as np, tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "#\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "urllib.request.urlretrieve(url, 'shakespeare.txt')\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as f :\n",
    "    text = f.read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Chars : \\n\", chars)\n",
    "char_to_idx = {c:i for i,c in enumerate(chars)}\n",
    "idx_to_char = {i:c for i,c in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "#\n",
    "seq_len = 50\n",
    "step = 3\n",
    "X, y = [], []\n",
    "for i in range(0, len(text)-seq_len, step):\n",
    "    X.append([char_to_idx[c] for c in text[i:i+seq_len]])\n",
    "    y.append(char_to_idx[text[i+seq_len]])\n",
    "print(\"X: \\n\", X)\n",
    "print(\"Y: \\n\", y)\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, vocab_size)\n",
    "print(\"X(Transformed): \\n\", X)\n",
    "print(\"Y(Transformed): \\n\", y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# === CHANGED MODEL SECTION ===\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(vocab_size, 128, input_length=seq_len),\n",
    "    layers.SimpleRNN(128, return_sequences=True),   # Changed from LSTM to SimpleRNN\n",
    "    layers.Dropout(0.2),\n",
    "    layers.SimpleRNN(128),                         # Changed from LSTM to SimpleRNN\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X, y, batch_size=128, epochs=3, callbacks=[early], verbose=1)\n",
    "\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print(f\"Final Model Accuracy: {acc:.4f}\")\n",
    "print(f\"Final Model Loss: {loss:.4f}\")\n",
    "\n",
    "#\n",
    "def generate(seed: str, length: int=200, temperature = 1.0):\n",
    "    seed_seq = seed.lower()[-seq_len:].ljust(seq_len, '\\x00')\n",
    "    x = np.array([char_to_idx.get(c, 0) for c in seed_seq]).reshape(1,seq_len)\n",
    "    result = seed\n",
    "\n",
    "    for _ in range(length):\n",
    "        probs = model.predict(x, verbose=0)[0]\n",
    "        probs = np.log(probs + 1e-12) / temperature\n",
    "        probs = np.exp(probs) / np.sum(np.exp(probs))\n",
    "        idx = np.random.choice(vocab_size, p=probs)\n",
    "        result += idx_to_char[idx]\n",
    "        x = np.roll(x, -1)\n",
    "        x[0, -1] = idx\n",
    "    return result\n",
    "print(\"\\n=== Sample generations ===\")\n",
    "for seed in [\"to be or not to be\", \"the king \", \"romeo, romeo, \"]:\n",
    "    print(f\"\\nSeed : {seed}\")\n",
    "    print(\"Gen  :\", generate(seed, length=120, temperature=0.9))\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "model.build(input_shape=(None, seq_len))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
